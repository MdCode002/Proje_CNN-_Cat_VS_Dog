# Projet CNN : Chats vs Chiens (Comparaison From Scratch vs Transfert Learning)

**Auteur :** Mouhamed DIOUF  
**GitHub :** [Mdcode002](https://github.com/Mdcode002)

---

## Objectif

Ce projet compare deux approches pour la classification d'images (Chats vs Chiens) en utilisant **PyTorch** :

- **Exp√©rience A : CNN From Scratch** ‚Äî Conception et entra√Ænement d‚Äôun r√©seau simple.
- **Exp√©rience B : Transfert Learning (ResNet18)** ‚Äî R√©utilisation d‚Äôun mod√®le pr√©-entra√Æn√© sur ImageNet.

L‚Äôobjectif est de mesurer l‚Äôimpact du transfert learning sur :
- la **vitesse de convergence**,
- la **performance (accuracy, recall, F1)**,
- la **robustesse** du mod√®le.

---

## Environnement & D√©pendances

Ex√©cution recommand√©e : **Google Colab (GPU activ√©)**

### Installation locale

```bash
pip install -r requirements.txt
```

**requirements.txt :**
```txt
numpy
matplotlib
torch>=2.0
torchvision>=0.15
scikit-learn
# torchmetrics==1.4.0 (optionnel)
```

**.gitignore :**
```gitignore
# Donn√©es
data/
Cat_Dog_data/

# Mod√®les sauvegard√©s
*.pt
*.pth
checkpoints/

# Environnements Python
*.env
venv/
.venv/

# Caches
__pycache__/
.ipynb_checkpoints/
```

---

## Organisation des Donn√©es

Jeu de donn√©es : **Kaggle Cats vs Dogs**

Structure :
```bash
Cat_Dog_data/
‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ cat/
‚îÇ   ‚îî‚îÄ‚îÄ dog/
‚îî‚îÄ‚îÄ test/
    ‚îú‚îÄ‚îÄ cat/
    ‚îî‚îÄ‚îÄ dog/
```
> 22 500 images pour l‚Äôentra√Ænement et 2 500 pour le test.

---

## Ex√©cution du Projet

Tout est contenu dans **notebook.ipynb**.

Reproductibilit√© :
```python
seed_everything(42)
```

### Pr√©-traitement & Augmentation
- **Train :** RandomRotation(30), RandomResizedCrop(224), RandomHorizontalFlip()
- **Val/Test :** Resize(255), CenterCrop(224)
- **Normalisation :** mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]

---

## Exp√©riences

### Exp√©rience A : CNN From Scratch

- **Architecture :** 3 blocs conv + batchnorm + relu + maxpool + dropout (p=0.3)
- **Epochs :** 12 ‚Äî **Batch size :** 32

**A.1 Adam**
```python
optimizer = Adam(lr=1e-3, weight_decay=1e-4)
scheduler = StepLR(step_size=5, gamma=0.5)
```

**A.2 SGD**
```python
optimizer = SGD(lr=0.03, momentum=0.9, weight_decay=5e-4)
scheduler = CosineAnnealingLR(T_max=12)
```

### Exp√©rience B : Transfert Learning (ResNet18)

**Architecture :**
```python
model.fc = nn.Sequential(nn.Dropout(0.4), nn.Linear(512, 2))
```

#### Phase 1 ‚Äî Entra√Ænement de la t√™te
- Gel des features
- Epochs : 6 ‚Äî Optimiseur : Adam (LR=1e-3)

#### Phase 2 ‚Äî Fine-tuning
- D√©gel complet
- Epochs : 8 ‚Äî Optimiseur : SGD (LR=1e-3, momentum=0.9)

---

## R√©sultats

| Mod√®le | Optimiseur | Scheduler | Val. Acc. | Test Acc. |
|---------|-------------|------------|------------|------------|
| CNN Scratch | Adam | StepLR | 76.67% | 79.92% |
| CNN Scratch | SGD | Cosine | 75.82% | ‚Äî |
| ResNet18 (Head) | Adam | StepLR | 93.6% | ‚Äî |
| ResNet18 (Finetune) | SGD | Cosine | 96.64% | **‚âà96.5%** |

**Analyse :**
- Le ResNet18 converge beaucoup plus vite (92% en 1 √©poque).
- Le mod√®le from scratch plafonne √† ~80% malgr√© la r√©gularisation.
- Le transfert learning offre une meilleure g√©n√©ralisation et stabilit√©.

---

## Rechargement & √âvaluation

```python
def make_scratch():
    return SmallCNN(num_classes=2)

model = load_best('checkpoints/cnn_scratch_best.pth', make_scratch)
criterion = nn.CrossEntropyLoss()
loss, acc, _ = evaluate(model, test_loader, criterion)
print(f"[Reloaded scratch] TEST ‚Äî acc={acc:.4f}")
```

---


## üìú Licence

Ce projet est distribu√© sous la licence **MIT**.

---
